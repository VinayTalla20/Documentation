helm install my-release bitnami/kube-prometheus
helm show values bitnami/kube-prometheus
helm show values prometheus-community/prometheus > prometheus-nginx.yaml

helm install prometheus prometheus-community/prometheus --values prometheus-nginx.yaml

 kubectl run -ti --rm=true busybox --image=busybox

wget -qO- 192.168.2.114:9113/metrics

kubectl get pods -l app=prometheus,component=server -o jsonpath={.items[0].metadata.name}

(kubectl get pods --namespace default -l "app=prometheus,component=server" -o jsonpath="{.items[0].metadata.name}")
nginx_ingress_nginx_connections_active

my-nginx-ingress-nginx-ingress
podinfo


my-nginx-ingress-nginx-ingress.nginx-ingress   ----  cluster DNS svc.namespace
svc.cluster.local   --- also can append this for above



apiVersion: v1 
kind: ConfigMap 
metadata: 
  name: locust-script 
data: 
  locustfile.py: |- 
    from locust import HttpUser, task, between 

    class QuickstartUser(HttpUser): 
        wait_time = between(0.7, 1.3) 

        @task 
        def hello_world(self): 
            self.client.get("/", headers={"Host": "example.com"}) 
--- 
apiVersion: apps/v1 
kind: Deployment 
metadata: 
  name: locust 
spec: 
  selector: 
    matchLabels: 
      app: locust 
  template: 
    metadata: 
      labels: 
        app: locust 
    spec: 
      containers: 
        - name: locust 
          image: locustio/locust 
          ports: 
            - containerPort: 8089 
          volumeMounts: 
            - mountPath: /home/locust 
              name: locust-script 
      volumes: 
        - name: locust-script 
          configMap: 
            name: locust-script 
--- 
apiVersion: v1 
kind: Service 
metadata: 
  name: locust 
spec: 
  ports: 
    - port: 8089 
      targetPort: 8089 
      nodePort: 30015 
  selector: 
    app: locust 
  type: LoadBalancer 




helm repo add kedacore https://kedacore.github.io/charts 

helm install keda kedacore/keda


KEDA  CRD object

apiVersion: keda.sh/v1alpha1 
kind: ScaledObject 
metadata: 
 name: nginx-scale 
spec: 
 scaleTargetRef: 
   kind: Deployment 
   name: main-nginx-ingress 
 minReplicaCount: 1 
 maxReplicaCount: 20 
 cooldownPeriod: 30 
 pollingInterval: 1 
 triggers: 
 - type: prometheus 
   metadata: 
     serverAddress: http://prometheus-server 
     metricName: nginx_connections_active_keda 
     query: | 
       sum(avg_over_time(nginx_ingress_nginx_connections_active{app="main-nginx-ingress"}[1m])) 
     threshold: "100"


prometheus panel 

nginx_ingress_nginx_http_requests_total{app="my-nginx-ingress-nginx-ingress", class="nginx", instance="192.168.2.114:9113", job="kubernetes-pods", namespace="nginx-ingress", pod="my-nginx-ingress-nginx-ingress-549cc5d657-rn45z", pod_template_hash="549cc5d657"}

please use netstat -ltnp, ss -nltp instead or lsof -i :8080 to verify specific port 



helm show values nginx-stable/nginx-ingress > stable-nginx.yaml
helm install my-nginx-ingress nginx-stable/nginx-ingress


http://my-nginx-ingress-nginx-ingress


 Warning  FailedScheduling  4m20s (x1 over 5m20s)  default-scheduler  0/2 nodes are available: 1 node(s) didn't have free ports for the requested pod ports, 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate.

change hostNetwork: true to false  in pods specification
